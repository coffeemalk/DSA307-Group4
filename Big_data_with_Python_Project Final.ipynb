{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0NhNOLpKDrNk"
   },
   "source": [
    "# 1. Import packages and datasets, define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "h9AUq3FFDrNm",
    "outputId": "758ba5ef-c11f-4935-a9cd-f730fb97adcf"
   },
   "outputs": [],
   "source": [
    "!sudo apt update\n",
    "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "#Check this site for the latest download link https://www.apache.org/dyn/closer.lua/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
    "#!wget -q https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
    "#!tar xf spark-3.2.1-bin-hadoop3.2.tgz\n",
    "!pip install -q findspark\n",
    "!pip install pyspark\n",
    "!pip install py4j\n",
    "\n",
    "import os\n",
    "import sys\n",
    "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "# os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop3.2\"\n",
    "\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "\n",
    "import pyspark\n",
    "\n",
    "from pyspark.sql import DataFrame, SparkSession\n",
    "from typing import List\n",
    "import pyspark.sql.types as T\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "spark= SparkSession \\\n",
    "       .builder \\\n",
    "       .appName(\"Our First Spark Example\") \\\n",
    "       .getOrCreate()\n",
    "\n",
    "spark\n",
    "\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "conf = SparkConf()\n",
    "conf.setMaster(\"local\").setAppName(\"My app\")\n",
    "sc = SparkContext.getOrCreate(conf)\n",
    "sc.master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-a_1kXtIEBAn",
    "outputId": "f2cb923e-1fc7-4791-d304-dab905138f37"
   },
   "outputs": [],
   "source": [
    "#Import smoking dataset parquet as a pyspark dataframe\n",
    "df = spark.read.parquet(\"smoking_dataset.parquet\")\n",
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E7FJiiHaXYgv"
   },
   "outputs": [],
   "source": [
    "# libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, LinearSVC, MultilayerPerceptronClassifier\n",
    "from xgboost.spark import SparkXGBClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.feature import PCA, StandardScaler\n",
    "from pyspark.ml.stat import Correlation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XrLOEYbS8LVA"
   },
   "outputs": [],
   "source": [
    "class RandomGridBuilder:\n",
    "  '''Grid builder for random search. Sets up grids for use in CrossValidator in Spark using values randomly sampled from user-provided distributions.\n",
    "  Distributions should be provided as lambda functions, so that the numbers are generated at call time.\n",
    "\n",
    "  Parameters:\n",
    "    num_models: Integer (Python) - number of models to generate hyperparameters for\n",
    "    seed: Integer (Python) - seed (optional, default is None)\n",
    "\n",
    "  Returns:\n",
    "    param_map: list of parameter maps to use in cross validation.\n",
    "\n",
    "  Example usage:\n",
    "    from pyspark.ml.classification import LogisticRegression\n",
    "    lr = LogisticRegression()\n",
    "    paramGrid = RandomGridBuilder(2)\\\n",
    "               .addDistr(lr.regParam, lambda: np.random.rand()) \\\n",
    "               .addDistr(lr.maxIter, lambda : np.random.randint(10))\\\n",
    "               .build()\n",
    "\n",
    "    Returns similar output as Spark ML class ParamGridBuilder and can be used in its place. The above paramGrid provides random hyperparameters for 2 models.\n",
    "    '''\n",
    "\n",
    "  def __init__(self, num_models, seed=None):\n",
    "    self._param_grid = {}\n",
    "    self.num_models = num_models\n",
    "    self.seed = seed\n",
    "\n",
    "  def addDistr(self, param, distr_generator):\n",
    "    '''Add distribution based on dictionary generated by function passed to addDistr.'''\n",
    "\n",
    "    if 'pyspark.ml.param.Param' in str(type(param)):\n",
    "      self._param_grid[param] = distr_generator\n",
    "    else:\n",
    "      raise TypeError('param must be an instance of Param')\n",
    "\n",
    "    return self\n",
    "\n",
    "  def build(self):\n",
    "    param_map = []\n",
    "    for n in range(self.num_models):\n",
    "      if self.seed:\n",
    "        # Set seeds for both numpy and random in case either is used for the random distribution\n",
    "        np.random.seed(self.seed + n)\n",
    "        np.random.seed(self.seed + n)\n",
    "      param_dict = {}\n",
    "      for param, distr in self._param_grid.items():\n",
    "        param_dict[param] = distr()\n",
    "      param_map.append(param_dict)\n",
    "\n",
    "    return param_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I_kyYW_mFCbZ"
   },
   "source": [
    "# 2. Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deriving summary statistics of BLDS and visualising proportion of prediabetic/diabetic individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get summary statistics based on BLDS\n",
    "df.describe([\"BLDS\"]).show()\n",
    "\n",
    "# Calculate the count of patients with BLDS > 126 (diabetic)\n",
    "diabetic_count = df.filter(df[\"BLDS\"] > 126).count()\n",
    "\n",
    "# Calculate the count of patients with BLDS > 100 but <= 126 (pre-diabetic)\n",
    "pre_diabetic_count = df.filter((df[\"BLDS\"] > 100) & (df[\"BLDS\"] <= 126)).count()\n",
    "\n",
    "# Calculate the proportions\n",
    "diabetic_proportion = diabetic_count / df.count()\n",
    "pre_diabetic_proportion = pre_diabetic_count / df.count()\n",
    "\n",
    "print(f\"Diabetic Proportion: {diabetic_proportion:.2%}\")\n",
    "print(f\"Pre-diabetic Proportion: {pre_diabetic_proportion:.2%}\")\n",
    "\n",
    "# Create visualisation\n",
    "labels = ['Diabetic (BLDS > 126)', 'Pre-diabetic (BLDS > 100 & <= 126)']\n",
    "proportions = [diabetic_proportion, pre_diabetic_proportion]\n",
    "fig, ax = plt.subplots()\n",
    "bars = ax.bar(labels, proportions, color=['red', 'blue'])\n",
    "ax.bar_label(bars, labels=[f\"{v*100:.2f}%\" for v in proportions], padding=8, fontsize=12)\n",
    "\n",
    "# Set plot labels\n",
    "ax.set_ylim(0, 1.0)\n",
    "ax.set_ylabel('Proportion of Patients in %')\n",
    "ax.set_title('Proportion of Patients by Blood Sugar Levels')\n",
    "ax.grid(axis='y')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZWuG95DLh_T"
   },
   "source": [
    "## Creating new target variable, diabetic, based on threshold bloodsugar of 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ti90dJMNI7X_",
    "outputId": "d54df97b-3c90-495f-922c-78844f84097a"
   },
   "outputs": [],
   "source": [
    "#Adding a column with boolean diabetic\n",
    "df = df.withColumn(\"diabetic\", df.BLDS >= 100)\n",
    "#casting the boolean to integar if model needs ?\n",
    "df = df.withColumn(\"diabetic_label\", df.diabetic.cast(\"double\"))\n",
    "# #Removing the original columns\n",
    "# df = df.drop(\"diabetic\", \"BLDS\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encoding and pipeline setup for subsequent models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P6ESqDqFFg9S",
    "outputId": "55b3c465-9ac5-4c8f-ca27-3e11b45ca1e5"
   },
   "outputs": [],
   "source": [
    "# Sex, DRK_YN need to be one hot encoded\n",
    "df.printSchema()\n",
    "\n",
    "# create StringIndexer\n",
    "sex_indexer = StringIndexer(inputCol=\"sex\", outputCol=\"Sex_Index\")\n",
    "DRK_YN_indexer = StringIndexer(inputCol=\"DRK_YN\", outputCol=\"DRK_YN_Index\")\n",
    "\n",
    "# create OneHotEncoder\n",
    "sex_encoder = OneHotEncoder(inputCol=\"Sex_Index\", outputCol=\"Sex_Vec\")\n",
    "DRK_YN_encoder = OneHotEncoder(inputCol=\"DRK_YN_Index\", outputCol=\"DRK_YN_Vec\")\n",
    "\n",
    "# make VectorAssembler\n",
    "vec_assembler = VectorAssembler(inputCols= [\"Sex_Vec\", \"DRK_YN_Vec\", \"age\", \"height\", \"weight\", \"waistline\", \"sight_left\", \"sight_right\", \"hear_left\", \"hear_right\", \"SBP\", \"DBP\", \"tot_chole\", \"HDL_chole\", \"LDL_chole\", \"triglyceride\", \"hemoglobin\", \"urine_protein\", \"serum_creatinine\", \"SGOT_AST\", \"SGOT_ALT\", \"gamma_GTP\", \"SMK_stat_type_cd\"], outputCol=\"features\")\n",
    "\n",
    "# StandardScaler to scale features\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\")\n",
    "\n",
    "# make pipeline\n",
    "df_pipe = Pipeline(stages=[sex_indexer, DRK_YN_indexer, sex_encoder, DRK_YN_encoder, vec_assembler, scaler])\n",
    "\n",
    "# fit and transform data\n",
    "piped_data = df_pipe.fit(df).transform(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E4-EJqhzFFig"
   },
   "source": [
    "# 3. Exploratory data analysis (EDA)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation matrix plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 596
    },
    "id": "AA1wxmf9LxTg",
    "outputId": "1244d7c2-3eb1-45cf-9191-ee95df83d6c2"
   },
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "\n",
    "numeric_columns = ['diabetic_label', \"age\", \"height\", \"weight\", \"waistline\", \"sight_left\", \"sight_right\", \"hear_left\", \"hear_right\", \"SBP\", \"DBP\", \"tot_chole\", \"HDL_chole\", \"LDL_chole\", \"triglyceride\", \"hemoglobin\", \"urine_protein\", \"serum_creatinine\", \"SGOT_AST\", \"SGOT_ALT\", \"gamma_GTP\", \"SMK_stat_type_cd\"]\n",
    "\n",
    "# make VectorAssembler for corr plot\n",
    "cor_vec_assembler = VectorAssembler(inputCols= numeric_columns , outputCol=\"features\")\n",
    "\n",
    "# transform data\n",
    "corr_data = cor_vec_assembler.transform(df)\n",
    "\n",
    "corr_matrix = Correlation.corr(corr_data, 'features').collect()[0][0]\n",
    "corr_matrix = corr_matrix.toArray().tolist()\n",
    "corr_matrix_df = pd.DataFrame(data=corr_matrix, columns = numeric_columns, index= numeric_columns)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16,5))\n",
    "sns.heatmap(corr_matrix_df,\n",
    "            xticklabels=corr_matrix_df.columns.values,\n",
    "            yticklabels=corr_matrix_df.columns.values,  cmap=\"inferno\", annot=True,fmt='.1g')\n",
    "plt.title('Correlation Matrix')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring optimal PCA component with plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 927
    },
    "id": "ocbwuUYk3VwA",
    "outputId": "f8380ee7-4bfe-40df-86d9-dd56b077bf0f"
   },
   "outputs": [],
   "source": [
    "#PCA\n",
    "\n",
    "#Loop to iterate through 1-10 dimensions of pca, to find the minimum number of PCA dimensions to capture 95% of variance\n",
    "explained_variance_list = []\n",
    "for i in range(1,11):\n",
    "  pca = PCA(k = i, inputCol = \"features\", outputCol= \"pca_features\")\n",
    "  pca_model = pca.fit(piped_data)\n",
    "  explained_variance = np.array(pca_model.explainedVariance)\n",
    "  sum_variance = np.sum(explained_variance)\n",
    "  explained_variance_list.append(sum_variance)\n",
    "\n",
    "#Plot to illustrate the number of dimensions we should select, to account for a threshold 95% of variance\n",
    "\n",
    "sns.lineplot(x = np.arange(1,11), y = explained_variance_list)\n",
    "plt.axhline(y= 0.95, color = 'red')\n",
    "plt.title(\"Plot of Total Explained Variance against k Principle Component Dimensions\")\n",
    "plt.xlabel(\"Principle Component Dimensions\")\n",
    "plt.ylabel(\"Total explained variance\")\n",
    "plt.show()\n",
    "\n",
    "#k = 5 is selected\n",
    "pca = PCA(k = 5, inputCol = \"features\", outputCol= \"pca_features\")\n",
    "#Separate fit needs to be done to get explained variance, cannot extract from a pipeline which is why pca needs to be separate\n",
    "pca_model = pca.fit(piped_data)\n",
    "piped_data_pca = pca_model.transform(piped_data)\n",
    "\n",
    "explained_variance = np.array(pca_model.explainedVariance)\n",
    "\n",
    "# Create a bar plot of explained variance by principle component\n",
    "sns.barplot(x=['PC1', 'PC2', 'PC3', 'PC4', 'PC5'], y=explained_variance)\n",
    "plt.title('Explained Variance by Principal Component')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pca exploration\n",
    "\n",
    "#PCA with k = 2\n",
    "pca_test = PCA(k = 2, inputCol = \"features\", outputCol= \"pca_features\")\n",
    "\n",
    "# make pipeline\n",
    "df_pipe_test = Pipeline(stages=[sex_indexer, DRK_YN_indexer, sex_encoder, DRK_YN_encoder, vec_assembler, scaler, pca_test])\n",
    "\n",
    "# fit and transform data\n",
    "piped_data_test = df_pipe_test.fit(df).transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot of variables mapped to 2 PC\n",
    "sns.scatterplot(x= test_df1.PC1, y = test_df1.PC2, s = 1)\n",
    "plt.title('Scatter plot of points in Principle component axis ')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principle Component 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = piped_data_test.select(\"pca_features\")\n",
    "test_df = test.toPandas()\n",
    "test_df_plot = pd.DataFrame(test_df[\"pca_features\"].to_list(), columns=['PC1', 'PC2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_df_plot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Q1 \u001b[38;5;241m=\u001b[39m \u001b[43mtest_df_plot\u001b[49m\u001b[38;5;241m.\u001b[39mquantile(\u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m      2\u001b[0m Q3 \u001b[38;5;241m=\u001b[39m test_df_plot\u001b[38;5;241m.\u001b[39mquantile(\u001b[38;5;241m0.9\u001b[39m)\n\u001b[1;32m      3\u001b[0m IQR \u001b[38;5;241m=\u001b[39m Q3 \u001b[38;5;241m-\u001b[39m Q1\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_df_plot' is not defined"
     ]
    }
   ],
   "source": [
    "Q1 = test_df_plot.quantile(0.1)\n",
    "Q3 = test_df_plot.quantile(0.9)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "test_df1 = test_df_plot[~((test_df_plot < (Q1 - 1.5 * IQR)) |(test_df_plot > (Q3 + 1.5 * IQR))).any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Final PCA conversion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA with k = 5\n",
    "pca = PCA(k = 5, inputCol = \"features\", outputCol= \"pca_features\")\n",
    "\n",
    "# make pipeline\n",
    "df_pipe = Pipeline(stages=[sex_indexer, DRK_YN_indexer, sex_encoder, DRK_YN_encoder, vec_assembler, scaler, pca])\n",
    "\n",
    "# fit and transform data\n",
    "piped_data = df_pipe.fit(df).transform(df)\n",
    "\n",
    "# split data into training and testing data\n",
    "training, test = piped_data.randomSplit([0.8, 0.2], seed=999) # set seed=999 for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UIyAr6iHJzLY"
   },
   "source": [
    "# 4. Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "euVShduljtAt"
   },
   "outputs": [],
   "source": [
    "# create evaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"diabetic_label\", predictionCol=\"prediction\", metricName=\"recallByLabel\", metricLabel=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iBCYOUh0klnP",
    "outputId": "fb8c4750-f875-46df-8845-96d54bb36287"
   },
   "outputs": [],
   "source": [
    "# create Logistic Regression model\n",
    "lr = LogisticRegression(featuresCol=\"scaled_features\", labelCol=\"diabetic_label\")\n",
    "\n",
    "# create and build parameter grid\n",
    "grid_lr = RandomGridBuilder(num_models=20, seed=999)\\\n",
    "               .addDistr(lr.regParam, lambda: np.random.uniform(0.001,1))\\\n",
    "               .addDistr(lr.elasticNetParam, lambda : np.random.uniform(0,1))\\\n",
    "               .build()\n",
    "\n",
    "# create CrossValidator\n",
    "cv = CrossValidator(estimator=lr, estimatorParamMaps=grid_lr, evaluator=evaluator, numFolds=5, seed=999)\n",
    "\n",
    "# fit cross validation models\n",
    "models = cv.fit(training)\n",
    "\n",
    "# extract best model\n",
    "best_lr = models.bestModel\n",
    "\n",
    "# predict on test data\n",
    "test_results = best_lr.transform(test)\n",
    "\n",
    "# get best model parameters\n",
    "print(best_lr.getRegParam())\n",
    "print(best_lr.getElasticNetParam())\n",
    "\n",
    "# evaluate the best model\n",
    "print(evaluator.evaluate(test_results))\n",
    "\n",
    "#Output results \n",
    "lr_results = pd.DataFrame([best_lr.getRegParam(), best_lr.getElasticNetParam(), evaluator.evaluate(test_results)], index = [\"alpha\", \"mixture\", \"Recall\"])\n",
    "lr_results.to_csv(\"Logistic Regression Results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "id": "PwAFp5DLwuCm",
    "outputId": "254fa1df-f35e-43dd-e5a3-8d07af55edf0"
   },
   "outputs": [],
   "source": [
    "#SVC classifier\n",
    "\n",
    "svc = LinearSVC(labelCol = \"diabetic_label\", featuresCol = \"scaled_features\")\n",
    "\n",
    "grid_svc = RandomGridBuilder(20, seed=999)\\\n",
    "               .addDistr(svc.regParam, lambda: np.random.rand()) \\\n",
    "                .build()\n",
    "\n",
    "grid_svc\n",
    "\n",
    "\n",
    "\n",
    "#Cross validation\n",
    "cv_svc = CrossValidator(estimator = svc, estimatorParamMaps = grid_svc, evaluator = evaluator, numFolds = 5, seed = 999)\n",
    "models_svc = cv_svc.fit(training)\n",
    "best_svc = models_svc.bestModel\n",
    "\n",
    "test_results_svc = best_svc.transform(test)\n",
    "\n",
    "# get the best model parameters\n",
    "bestModelIndex = np.argmax(models_svc.avgMetrics)\n",
    "print(grid_svc[bestModelIndex][svc.regParam])\n",
    "\n",
    "print(evaluator.evaluate(test_results_svc))\n",
    "\n",
    "#Output results \n",
    "svc_results = pd.DataFrame([grid_svc[bestModelIndex][svc.regParam], evaluator.evaluate(test_results_svc)], index=[\"alpha\", \"recall\"])\n",
    "svc_results.to_csv(\"SVC Results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nH9lLRy1kmR4"
   },
   "outputs": [],
   "source": [
    "#Random forest classifier\n",
    "\n",
    "rf = RandomForestClassifier(labelCol = \"diabetic_label\", featuresCol = \"scaled_features\", seed = 999)\n",
    "\n",
    "# random parameter grid\n",
    "grid_rf = RandomGridBuilder(20, seed=999)\n",
    "#backslash needed for syntax\n",
    "grid_rf = grid_rf.addDistr(rf.numTrees, lambda: np.random.randint(50, 500))\\\n",
    "                  .addDistr(rf.maxDepth, lambda:np.random.randint(5) ) \\\n",
    "                  .addDistr(rf.featureSubsetStrategy, lambda: str(np.random.randint(24)))\n",
    "grid_rf = grid_rf.build()\n",
    "\n",
    "#Cross validation\n",
    "cv_rf = CrossValidator(estimator = rf, estimatorParamMaps = grid_rf, evaluator = evaluator, numFolds = 5, seed = 999)\n",
    "models_rf = cv_rf.fit(training)\n",
    "best_rf = models_rf.bestModel\n",
    "\n",
    "test_results_rf = best_rf.transform(test)\n",
    "\n",
    "# get the best model parameters\n",
    "bestModelIndex = np.argmax(models_rf.avgMetrics)\n",
    "print(grid_rf[bestModelIndex][rf.numTrees])\n",
    "print(grid_rf[bestModelIndex][rf.maxDepth])\n",
    "print(grid_rf[bestModelIndex][rf.featureSubsetStrategy])\n",
    "\n",
    "print(evaluator.evaluate(test_results_rf))\n",
    "\n",
    "#Output results \n",
    "rf_results = pd.DataFrame([grid_rf[bestModelIndex][rf.numTrees],grid_rf[bestModelIndex][rf.maxDepth], grid_rf[bestModelIndex][rf.featureSubsetStrategy],evaluator.evaluate(test_results_rf)], index=[\"ntree\", \"max_depth\", \"mtry\" , \"recall\"])\n",
    "rf_results.to_csv(\"RF Results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qWTeiahhKUJy"
   },
   "outputs": [],
   "source": [
    "xgb = SparkXGBClassifier(\n",
    "  features_col=\"scaled_features\",\n",
    "  label_col=\"diabetic_label\",\n",
    "  seed=999,\n",
    "  n_estimators=100,\n",
    "  num_workers=sc.defaultParallelism\n",
    ")\n",
    "\n",
    "grid = RandomGridBuilder(num_models=20, seed=999)\\\n",
    "               .addDistr(xgb.learning_rate, lambda: np.random.uniform(0.001,1))\\\n",
    "               .addDistr(xgb.reg_alpha, lambda : np.random.uniform(0,5))\\\n",
    "               .addDistr(xgb.reg_lambda, lambda : np.random.uniform(0,5))\\\n",
    "               .addDistr(xgb.gamma, lambda: np.random.uniform(0,3))\\\n",
    "               .addDistr(xgb.max_depth, lambda : np.random.randint(4,11))\\\n",
    "               .build()\n",
    "\n",
    "# create CrossValidator\n",
    "cv = CrossValidator(estimator=xgb, estimatorParamMaps=grid, evaluator=evaluator, numFolds=5, seed=999)\n",
    "\n",
    "# fit cross validation models\n",
    "models = cv.fit(training)\n",
    "\n",
    "# extract best model\n",
    "best_model = models.bestModel\n",
    "\n",
    "# predict on test data\n",
    "test_results = best_model.transform(test)\n",
    "\n",
    "# get the best model parameters\n",
    "bestModelIndex = np.argmax(models.avgMetrics)\n",
    "print(grid[bestModelIndex][xgb.learning_rate])\n",
    "print(grid[bestModelIndex][xgb.reg_alpha])\n",
    "print(grid[bestModelIndex][xgb.reg_lambda])\n",
    "print(grid[bestModelIndex][xgb.gamma])\n",
    "print(grid[bestModelIndex][xgb.max_depth])\n",
    "\n",
    "# evaluate the best model\n",
    "print(evaluator.evaluate(test_results))\n",
    "\n",
    "#Output results \n",
    "xgb_results = pd.DataFrame([grid[bestModelIndex][xgb.learning_rate],\n",
    "                           grid[bestModelIndex][xgb.reg_alpha],\n",
    "                           grid[bestModelIndex][xgb.reg_lambda],\n",
    "                           grid[bestModelIndex][xgb.gamma],\n",
    "                           grid[bestModelIndex][xgb.max_depth],\n",
    "                           evaluator.evaluate(test_results)], \n",
    "                           index=[\"learning rate\", \"reg_alpha\", \"reg_lambda\" , \"gamma\", \"max_depth\", \"recall\"])\n",
    "xgb_results.to_csv(\"xgb Results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RdffMLNfKLCc"
   },
   "outputs": [],
   "source": [
    "# MultilayerPerceptronClassifier\n",
    "\n",
    "# specify layers for the neural network:\n",
    "# input layer of size 23 (features), 1 hidden layer of size 10 and output layer of size 2 (classes)\n",
    "layers = [23, 16, 8, 2]\n",
    "\n",
    "# create the trainer and set its parameters\n",
    "trainer = MultilayerPerceptronClassifier(featuresCol=\"scaled_features\", labelCol=\"diabetic_label\", maxIter=100, layers=layers, seed=999)\n",
    "\n",
    "# build grid\n",
    "grid = RandomGridBuilder(num_models=20, seed=999)\\\n",
    "               .addDistr(trainer.stepSize, lambda: np.random.uniform(0.001,0.1))\\\n",
    "               .addDistr(trainer.blockSize, lambda : np.random.randint(1,501))\\\n",
    "               .build()\n",
    "\n",
    "# create CrossValidator\n",
    "cv = CrossValidator(estimator=trainer, estimatorParamMaps=grid, evaluator=evaluator, numFolds=5, seed=999)\n",
    "\n",
    "# fit cross validation models\n",
    "models = cv.fit(training)\n",
    "\n",
    "# extract best model\n",
    "best_model = models.bestModel\n",
    "\n",
    "# predict on test data\n",
    "test_results = best_model.transform(test)\n",
    "\n",
    "# get best model parameters\n",
    "print(best_model.getStepSize())\n",
    "print(best_model.getBlockSize())\n",
    "\n",
    "# evaluate the best model\n",
    "print(evaluator.evaluate(test_results))\n",
    "\n",
    "#Output results \n",
    "mlp_results = pd.DataFrame([best_model.getStepSize(),\n",
    "                           best_model.getBlockSize(),\n",
    "                           evaluator.evaluate(test_results)], \n",
    "                           index=[\"step size\", \"block size\",\"recall\"])\n",
    "mlp_results.to_csv(\"mlp Results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EXJT1JRkJ4hi"
   },
   "source": [
    "# 5. PCA approach\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4grjLH7MtH7J"
   },
   "outputs": [],
   "source": [
    "# create Logistic Regression model\n",
    "lr = LogisticRegression(featuresCol=\"pca_features\", labelCol=\"diabetic_label\")\n",
    "\n",
    "# create and build parameter grid\n",
    "grid = RandomGridBuilder(num_models=20, seed=999)\\\n",
    "               .addDistr(lr.regParam, lambda: np.random.uniform(0.001,1))\\\n",
    "               .addDistr(lr.elasticNetParam, lambda : np.random.uniform(0,1))\\\n",
    "               .build()\n",
    "\n",
    "# create CrossValidator\n",
    "cv = CrossValidator(estimator=lr, estimatorParamMaps=grid, evaluator=evaluator, numFolds=5, seed=999)\n",
    "\n",
    "# fit cross validation models\n",
    "models = cv.fit(training)\n",
    "\n",
    "# extract best model\n",
    "best_lr = models.bestModel\n",
    "\n",
    "# predict on test data\n",
    "test_results = best_lr.transform(test)\n",
    "\n",
    "# get best model parameters\n",
    "print(best_lr.getRegParam())\n",
    "print(best_lr.getElasticNetParam())\n",
    "\n",
    "# evaluate the best model\n",
    "print(evaluator.evaluate(test_results))\n",
    "\n",
    "#Output results \n",
    "lr_results = pd.DataFrame([best_lr.getRegParam(), best_lr.getElasticNetParam(), evaluator.evaluate(test_results)], index = [\"alpha\", \"mixture\", \"Recall\"])\n",
    "lr_results.to_csv(\"PCA Logistic Regression Results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IEZf3klOkJJP"
   },
   "outputs": [],
   "source": [
    "#SVC classifier\n",
    "\n",
    "svc = LinearSVC(labelCol = \"diabetic_label\", featuresCol = \"pca_features\")\n",
    "\n",
    "\n",
    "grid_svc = RandomGridBuilder(20, seed = 999)\\\n",
    "               .addDistr(svc.regParam, lambda: np.random.rand()) \\\n",
    "                .build()\n",
    "\n",
    "grid_svc\n",
    "\n",
    "\n",
    "\n",
    "#Cross validation\n",
    "cv_svc = CrossValidator(estimator = svc, estimatorParamMaps = grid_svc, evaluator = evaluator, numFolds = 5, seed = 999)\n",
    "models_svc = cv_svc.fit(training)\n",
    "best_svc = models_svc.bestModel\n",
    "\n",
    "test_results_svc = best_svc.transform(test)\n",
    "\n",
    "# get the best model parameters\n",
    "bestModelIndex = np.argmax(models_svc.avgMetrics)\n",
    "print(grid_svc[bestModelIndex][svc.regParam])\n",
    "\n",
    "print(evaluator.evaluate(test_results_svc))\n",
    "\n",
    "#Output results \n",
    "svc_results = pd.DataFrame([grid_svc[bestModelIndex][svc.regParam], evaluator.evaluate(test_results_svc)], index=[\"alpha\", \"recall\"])\n",
    "svc_results.to_csv(\"PCA SVC Results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "0sOBdZ4v5Ny3",
    "outputId": "c54c4aca-c090-4138-93c4-17f4261e7dab"
   },
   "outputs": [],
   "source": [
    "#Random forest classifier\n",
    "\n",
    "rf = RandomForestClassifier(labelCol = \"diabetic_label\", featuresCol = \"pca_features\", seed = 999)\n",
    "\n",
    "# random parameter grid\n",
    "grid_rf = RandomGridBuilder(20, seed = 999)\n",
    "#backslash needed for syntax\n",
    "grid_rf = grid_rf.addDistr(rf.numTrees, lambda: np.random.randint(50, 500))\\\n",
    "                  .addDistr(rf.maxDepth, lambda:np.random.randint(5) ) \\\n",
    "                  .addDistr(rf.featureSubsetStrategy, lambda: str(np.random.randint(5)))\n",
    "grid_rf = grid_rf.build()\n",
    "\n",
    "#Cross validation\n",
    "cv_rf = CrossValidator(estimator = rf, estimatorParamMaps = grid_rf, evaluator = evaluator, numFolds = 5, seed = 999)\n",
    "models_rf = cv_rf.fit(training)\n",
    "best_rf = models_rf.bestModel\n",
    "\n",
    "test_results_rf = best_rf.transform(test)\n",
    "\n",
    "# get the best model parameters\n",
    "bestModelIndex = np.argmax(models_rf.avgMetrics)\n",
    "print(grid_rf[bestModelIndex][rf.numTrees])\n",
    "print(grid_rf[bestModelIndex][rf.maxDepth])\n",
    "print(grid_rf[bestModelIndex][rf.featureSubsetStrategy])\n",
    "\n",
    "print(evaluator.evaluate(test_results_rf))\n",
    "\n",
    "#Output results \n",
    "rf_results = pd.DataFrame([grid_rf[bestModelIndex][rf.numTrees],grid_rf[bestModelIndex][rf.maxDepth], grid_rf[bestModelIndex][rf.featureSubsetStrategy],evaluator.evaluate(test_results_rf)], index=[\"ntree\", \"max_depth\", \"mtry\" , \"recall\"])\n",
    "rf_results.to_csv(\"PCA RF Results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6QT6ECQGkMy0"
   },
   "outputs": [],
   "source": [
    "xgb = SparkXGBClassifier(\n",
    "  features_col=\"pca_features\",\n",
    "  label_col=\"diabetic_label\",\n",
    "  seed=999,\n",
    "  n_estimators=100,\n",
    "  num_workers=sc.defaultParallelism\n",
    ")\n",
    "\n",
    "grid = RandomGridBuilder(num_models=20, seed=999)\\\n",
    "               .addDistr(xgb.learning_rate, lambda: np.random.uniform(0.001,1))\\\n",
    "               .addDistr(xgb.reg_alpha, lambda : np.random.uniform(0,5))\\\n",
    "               .addDistr(xgb.reg_lambda, lambda : np.random.uniform(0,5))\\\n",
    "               .addDistr(xgb.gamma, lambda: np.random.uniform(0,3))\\\n",
    "               .addDistr(xgb.max_depth, lambda : np.random.randint(4,11))\\\n",
    "               .build()\n",
    "\n",
    "# create CrossValidator\n",
    "cv = CrossValidator(estimator=xgb, estimatorParamMaps=grid, evaluator=evaluator, numFolds=5, seed=999)\n",
    "\n",
    "# fit cross validation models\n",
    "models = cv.fit(training)\n",
    "\n",
    "# extract best model\n",
    "best_model = models.bestModel\n",
    "\n",
    "# predict on test data\n",
    "test_results = best_model.transform(test)\n",
    "\n",
    "# get the best model parameters\n",
    "bestModelIndex = np.argmax(models.avgMetrics)\n",
    "print(grid[bestModelIndex][xgb.learning_rate])\n",
    "print(grid[bestModelIndex][xgb.reg_alpha])\n",
    "print(grid[bestModelIndex][xgb.reg_lambda])\n",
    "print(grid[bestModelIndex][xgb.gamma])\n",
    "print(grid[bestModelIndex][xgb.max_depth])\n",
    "\n",
    "# evaluate the best model\n",
    "print(evaluator.evaluate(test_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KX2QPLafkRbT"
   },
   "outputs": [],
   "source": [
    "# MultilayerPerceptronClassifier\n",
    "\n",
    "# specify layers for the neural network:\n",
    "# input layer of size 23 (features), 1 hidden layer of size 10 and output layer of size 2 (classes)\n",
    "layers = [5, 16, 8, 2]\n",
    "\n",
    "# create the trainer and set its parameters\n",
    "trainer = MultilayerPerceptronClassifier(featuresCol=\"pca_features\", labelCol=\"diabetic_label\", maxIter=100, layers=layers, seed=999)\n",
    "\n",
    "# build grid\n",
    "grid = RandomGridBuilder(num_models=20, seed=999)\\\n",
    "               .addDistr(trainer.stepSize, lambda: np.random.uniform(0.001,0.1))\\\n",
    "               .addDistr(trainer.blockSize, lambda : np.random.randint(1,501))\\\n",
    "               .build()\n",
    "\n",
    "# create CrossValidator\n",
    "cv = CrossValidator(estimator=trainer, estimatorParamMaps=grid, evaluator=evaluator, numFolds=5, seed=999)\n",
    "\n",
    "# fit cross validation models\n",
    "models = cv.fit(training)\n",
    "\n",
    "# extract best model\n",
    "best_model = models.bestModel\n",
    "\n",
    "# predict on test data\n",
    "test_results = best_model.transform(test)\n",
    "\n",
    "# get best model parameters\n",
    "print(best_model.getStepSize())\n",
    "print(best_model.getBlockSize())\n",
    "\n",
    "# evaluate the best model\n",
    "print(evaluator.evaluate(test_results))\n",
    "\n",
    "\n",
    "#Output results \n",
    "mlp_results = pd.DataFrame([best_model.getStepSize(),\n",
    "                           best_model.getBlockSize(),\n",
    "                           evaluator.evaluate(test_results)], \n",
    "                           index=[\"step size\", \"block size\",\"recall\"])\n",
    "mlp_results.to_csv(\"PCA mlp Results.csv\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
